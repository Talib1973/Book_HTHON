"use strict";(globalThis.webpackChunkbook_hthon=globalThis.webpackChunkbook_hthon||[]).push([[852],{4280(e,n,s){s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"capstone/index","title":"Capstone Project","description":"Overview","source":"@site/docs/capstone/index.md","sourceDirName":"capstone","slug":"/capstone/","permalink":"/docs/capstone/","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/capstone/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"index","title":"Capstone Project","sidebar_position":1},"sidebar":"roboticsSidebar","previous":{"title":"Module 4 - Vision-Language-Action (VLA)","permalink":"/docs/module-4-vla/"}}');var t=s(4848),o=s(8453);const r={id:"index",title:"Capstone Project",sidebar_position:1},a="Capstone Project: End-to-End Humanoid Robotics System",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Project Goals",id:"project-goals",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Deliverables",id:"deliverables",level:2},{value:"Suggested Tasks",id:"suggested-tasks",level:2},{value:"Evaluation Criteria",id:"evaluation-criteria",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"capstone-project-end-to-end-humanoid-robotics-system",children:"Capstone Project: End-to-End Humanoid Robotics System"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"The capstone project integrates all four modules to build a complete humanoid robotics system capable of understanding natural language commands, planning actions in simulation, and executing tasks on physical hardware."}),"\n",(0,t.jsx)(n.h2,{id:"project-goals",children:"Project Goals"}),"\n",(0,t.jsx)(n.p,{children:"Design and implement a humanoid robot that can:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Understand"}),": Process natural language task instructions using VLA models"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Plan"}),": Generate action sequences in Isaac Sim digital twin"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Execute"}),": Deploy ROS 2 control to physical humanoid hardware"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Learn"}),": Improve from demonstrations and feedback"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"User Speech \u2192 Whisper \u2192 LLM Task Planner\n                            \u2193\n                    VLA Action Predictor\n                            \u2193\n                    Isaac Sim Validation\n                            \u2193\n                    ROS 2 Hardware Control\n"})}),"\n",(0,t.jsx)(n.h2,{id:"deliverables",children:"Deliverables"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Design Document"}),": System architecture, component integration plan"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Simulation Demo"}),": End-to-end task execution in Isaac Sim"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hardware Demo"}),": Physical humanoid executing VLA-commanded task"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Final Report"}),": Technical implementation, challenges, future work"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"suggested-tasks",children:"Suggested Tasks"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Pick-and-place with natural language instructions"}),"\n",(0,t.jsx)(n.li,{children:"Multi-object sorting based on visual properties"}),"\n",(0,t.jsx)(n.li,{children:"Tool use for assembly tasks"}),"\n",(0,t.jsx)(n.li,{children:"Human-robot collaboration scenarios"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"evaluation-criteria",children:"Evaluation Criteria"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Technical Depth"}),": Integration of all 4 modules"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Robustness"}),": Error handling and edge cases"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Innovation"}),": Novel applications or improvements"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Documentation"}),": Clear explanation of design decisions"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453(e,n,s){s.d(n,{R:()=>r,x:()=>a});var i=s(6540);const t={},o=i.createContext(t);function r(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);